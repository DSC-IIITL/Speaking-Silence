{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\photos\\\\compressed_images\\\\completely_biased\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\photos\\\\mask_of_compressed_img\\\\completely_biased\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{original_PATH}train\\\\'\n",
    "test_data_dir = f'{original_PATH}test\\\\'\n",
    "# validation_data_dir = f'{original_PATH}valid\\\\'\n",
    "\n",
    "mask_train_data_dir = f'{mask_PATH}train\\\\'\n",
    "mask_test_data_dir = f'{mask_PATH}test\\\\'\n",
    "# mask_validation_data_dir = f'{mask_PATH}valid\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(train_data_dir)\n",
    "for c in classes:\n",
    "    class_path=train_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_train_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(test_data_dir)\n",
    "for c in classes:\n",
    "    class_path=test_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_test_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(validation_data_dir)\n",
    "for c in classes:\n",
    "    class_path=validation_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        detector = skinDetector(class_path+img_name, mask_validation_data_dir+c+'\\\\'+img_name)\n",
    "        detector.find_skin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert test photos to masked_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\test_videos\\\\photos\\\\test2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\test_videos\\\\photos\\\\test3_mask\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(original_PATH)\n",
    "for img in images:\n",
    "    img_name=img\n",
    "    detector = skinDetector(original_PATH+img_name, mask_PATH+'\\\\2'+img_name)\n",
    "    detector.find_skin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert custom photos mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_PATH = 'F:\\\\temp\\\\photos\\\\custom_sign\\\\food\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_PATH = 'F:\\\\temp\\\\photos\\\\custom_sign\\\\mask\\\\food\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(original_PATH)\n",
    "for img in images:\n",
    "    img_name=img\n",
    "    detector = skinDetector(original_PATH+img_name, mask_PATH+'\\\\'+img_name)\n",
    "    detector.find_skin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Open a simple image\n",
    "img=cv2.imread(\"F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\a\\\\3.png\")\n",
    "\n",
    "#converting from gbr to hsv color space\n",
    "img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#skin color range for hsv color space \n",
    "HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) \n",
    "HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#converting from gbr to YCbCr color space\n",
    "img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "#skin color range for hsv color space \n",
    "YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) \n",
    "YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "\n",
    "#merge skin detection (YCbCr and hsv)\n",
    "global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)\n",
    "global_mask=cv2.medianBlur(global_mask,3)\n",
    "global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))\n",
    "\n",
    "\n",
    "HSV_result = cv2.bitwise_not(HSV_mask)\n",
    "YCrCb_result = cv2.bitwise_not(YCrCb_mask)\n",
    "global_result=cv2.bitwise_not(global_mask)\n",
    "\n",
    "\n",
    "#show results\n",
    "# cv2.imshow(\"1_HSV.jpg\",HSV_result)\n",
    "# cv2.imshow(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "# cv2.imshow(\"3_global_result.jpg\",global_result)\n",
    "# cv2.imshow(\"Image.jpg\",img)\n",
    "cv2.imwrite(\"1_HSV.jpg\",HSV_result)\n",
    "cv2.imwrite(\"2_YCbCr.jpg\",YCrCb_result)\n",
    "cv2.imwrite(\"3_global_result.jpg\",global_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"F:\\\\Swastik\\\\study\\\\ml\\\\datasets\\\\speaking_silence_v2\\\\1\\\\train\\\\a\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'F:\\\\temp\\\\photos\\\\original\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{PATH}train\\\\'\n",
    "validation_data_dir = f'{PATH}test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, imageName,imagePath):\n",
    "        self.image = cv2.imread(imageName)\n",
    "        self.image_path=imagePath\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(self.image_path,output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = skinDetector(\"F:\\\\cropped.jpg\", \"F:\\\\output.jpg\")\n",
    "detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=os.listdir(train_data_dir)\n",
    "for c in classes:\n",
    "    class_path=train_data_dir+c+'\\\\';\n",
    "    images=os.listdir(class_path)\n",
    "    for img in images:\n",
    "        img_name=img\n",
    "        Skindet(class_path,c,img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_path+ img_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
