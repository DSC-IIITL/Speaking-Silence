{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model('F:\\\\temp\\\\models\\\\model_9classes_v6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skinDetector(object):\n",
    "    #class constructor\n",
    "    def __init__(self, img):\n",
    "        self.image = img\n",
    "#         self.image_path=img\n",
    "        if self.image is None:\n",
    "            print(\"IMAGE NOT FOUND\")\n",
    "            exit(1)                          \n",
    "        #self.image = cv2.resize(self.image,(600,600),cv2.INTER_AREA)\t\n",
    "        self.HSV_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
    "        self.YCbCr_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2YCR_CB)\n",
    "        self.binary_mask_image = self.HSV_image\n",
    "#================================================================================================================================\n",
    "    #function to process the image and segment the skin using the HSV and YCbCr colorspaces, followed by the Watershed algorithm\n",
    "    def find_skin(self):\n",
    "        self.__color_segmentation()\n",
    "        self.__region_based_segmentation()\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Apply a threshold to an HSV and YCbCr images, the used values were based on current research papers along with some\n",
    "    # empirical tests and visual evaluation\n",
    "    def __color_segmentation(self):\n",
    "        lower_HSV_values = np.array([0, 40, 0], dtype = \"uint8\")\n",
    "        upper_HSV_values = np.array([25, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "        lower_YCbCr_values = np.array((0, 138, 67), dtype = \"uint8\")\n",
    "        upper_YCbCr_values = np.array((255, 173, 133), dtype = \"uint8\")\n",
    "\n",
    "        #A binary mask is returned. White pixels (255) represent pixels that fall into the upper/lower.\n",
    "        mask_YCbCr = cv2.inRange(self.YCbCr_image, lower_YCbCr_values, upper_YCbCr_values)\n",
    "        mask_HSV = cv2.inRange(self.HSV_image, lower_HSV_values, upper_HSV_values) \n",
    "\n",
    "        self.binary_mask_image = cv2.add(mask_HSV,mask_YCbCr)\n",
    "\n",
    "#================================================================================================================================\n",
    "    #Function that applies Watershed and morphological operations on the thresholded image\n",
    "    def __region_based_segmentation(self):\n",
    "        #morphological operations\n",
    "        image_foreground = cv2.erode(self.binary_mask_image,None,iterations = 3)     \t#remove noise\n",
    "        dilated_binary_image = cv2.dilate(self.binary_mask_image,None,iterations = 3)   #The background region is reduced a little because of the dilate operation\n",
    "        ret,image_background = cv2.threshold(dilated_binary_image,1,128,cv2.THRESH_BINARY)  #set all background regions to 128\n",
    "\n",
    "        image_marker = cv2.add(image_foreground,image_background)   #add both foreground and backgroud, forming markers. The markers are \"seeds\" of the future image regions.\n",
    "        image_marker32 = np.int32(image_marker) #convert to 32SC1 format\n",
    "\n",
    "        cv2.watershed(self.image,image_marker32)\n",
    "        m = cv2.convertScaleAbs(image_marker32) #convert back to uint8 \n",
    "\n",
    "        #bitwise of the mask with the input image\n",
    "        ret,image_mask = cv2.threshold(m,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        output = cv2.bitwise_and(self.image,self.image,mask = image_mask)\n",
    "        cv2.imwrite(\"F:\\\\temp\\\\output.jpg\",output)\n",
    "        #show the images\n",
    "#         self.show_image(self.image)\n",
    "#         self.show_image(image_mask)\n",
    "#         self.show_image(output)\n",
    "\n",
    "\n",
    "#================================================================================================================================\n",
    "    def show_image(self, image):\n",
    "        cv2.imshow(\"Image\",image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=cv2.imread('F:\\\\temp\\\\test_videos\\\\photos\\\\test1\\\\frame10.jpg')\n",
    "# detector = skinDetector(x)\n",
    "# detector.find_skin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmentor = ImageDataGenerator(samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('F:\\\\temp\\\\test_videos\\\\test1.mp4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "text=\"\"\n",
    "while success:\n",
    "#     cv2.imwrite(\"F:\\\\temp\\\\test_videos\\\\photos\\\\test2\\\\frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "    detector = skinDetector(image)\n",
    "    detector.find_skin()\n",
    "    if(count%15==0):\n",
    "#         mask = cv2.imread(\"F:\\\\temp\\\\output.jpg\")\n",
    "        x = cv2.imread(\"F:\\\\temp\\\\output.jpg\").reshape(1,216,384,3)\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        x = train_data_augmentor.standardize(x)\n",
    "        pred=loaded_model.predict(x)\n",
    "        val=np.argmax(pred)\n",
    "        if(val==0):\n",
    "            str=\"a\"\n",
    "        if(val==1):\n",
    "            str=\"d\"\n",
    "        if(val==2):\n",
    "            str=\"f\"\n",
    "        if(val==3):\n",
    "            str=\"g\"\n",
    "        if(val==4):\n",
    "            str=\"h\"\n",
    "        if(val==5):\n",
    "            str=\"i\"\n",
    "        if(val==6):\n",
    "            str=\"k\"\n",
    "        if(val==7):\n",
    "            str=\"l\"\n",
    "        if(val==8):\n",
    "            str=\"o\"\n",
    "        if(text!=\"\"):\n",
    "            last=text[-1]\n",
    "            if(str!=last):\n",
    "                text=text+\" \"+str\n",
    "        else:\n",
    "            text=text+str\n",
    "    mask = cv2.imread(\"F:\\\\temp\\\\output.jpg\")\n",
    "    cv2.putText(image, str, (280,50), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0),4)\n",
    "    cv2.imshow(\"Image2\", mask)\n",
    "    cv2.imshow(\"Image\",image)\n",
    "    success,image = vidcap.read()\n",
    "#   print('Read a new frame: ', success)\n",
    "    count += 1\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if(key_pressed==ord('a')):\n",
    "        break\n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmentor = ImageDataGenerator(samplewise_center=True, \n",
    "                                    samplewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"dfdsfgf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(\"F:\\\\temp\\\\output.jpg\").reshape(1,216,384,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data_augmentor.standardize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=loaded_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()  \n",
    "engine.say(text)\n",
    "engine.runAndWait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('F:\\\\temp\\\\test_videos\\\\test1.mp4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    print(type(image))\n",
    "#     cv2.imshow(\"Image\",image)\n",
    "    success,image = vidcap.read()\n",
    "    if(count==10): x=image\n",
    "#     cv2.imshow(\"Image\",image)\n",
    "#   print('Read a new frame: ', success)\n",
    "    count += 1\n",
    "# vidcap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"F:\\\\temp\\\\output.jpg\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cv2.imread(\"F:\\\\temp\\\\output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
